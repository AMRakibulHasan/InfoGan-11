{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.backends import cudnn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "from InfoGan import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Helper Function for Image Loading\n",
    "class ImageFolder(data.Dataset):\n",
    "    def __init__(self, root, transform=None):  # Initializes image paths and preprocessing module.\n",
    "        self.image_paths = list(map(lambda x: os.path.join(root, x), os.listdir(root)))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):  # Reads an image from a file and preprocesses it and returns.\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):  # Returns the total number of image files.\n",
    "        return len(self.image_paths)\n",
    "\n",
    "##### Helper Function for GPU Training\n",
    "def to_variable(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "##### Helper Function for Math\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "# InfoGAN Function (Gaussian)\n",
    "def gen_cc(n_size, dim):\n",
    "    return torch.Tensor(np.random.randn(n_size, dim) * 0.5 + 0.0)\n",
    "\n",
    "# InfoGAN Function (Multi-Nomial)\n",
    "def gen_dc(n_size, dim):\n",
    "    codes=[]\n",
    "    code = np.zeros((n_size, dim))\n",
    "    random_cate = np.random.randint(0, dim, n_size)\n",
    "    code[range(n_size), random_cate] = 1\n",
    "    codes.append(code)\n",
    "    codes = np.concatenate(codes,1)\n",
    "    return torch.Tensor(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cudnn.benchmark = True\n",
    "\n",
    "params = {}\n",
    "params['image_size'] = 28 # 28 for mnist\n",
    "params['z_dim'] = 62\n",
    "params['batch_size'] = 64\n",
    "params['num_workers'] = 4\n",
    "params['num_epochs'] = 30\n",
    "\n",
    "#optimization params\n",
    "params['lrD'] = 0.0002  # Learning rate for Discriminator\n",
    "params['lrG'] = 0.001   # Learning rate for Generator\n",
    "params['beta1'] = 0.5   # Momentum 1 in Adam\n",
    "params['beta2'] = 0.999 # Momentum 2 in Adam\n",
    "\n",
    "#infoGan params\n",
    "params['cc_dim'] = 1\n",
    "params['dc_dim'] = 10\n",
    "params['continuous_weight'] = 0.5\n",
    "\n",
    "#misc\n",
    "params['db'] = 'mnist'\n",
    "params['sample_size'] = 100\n",
    "params['model_path'] = './model'\n",
    "params['sample_path'] = './results'\n",
    "params['log_step'] = 50\n",
    "params['sample_step'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((params['image_size'], params['image_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "dataset = datasets.MNIST('./MNIST', train=True, transform=transform, target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = data.DataLoader(dataset = dataset,\n",
    "                              batch_size = params['batch_size'],\n",
    "                              shuffle = True,\n",
    "                              num_workers = params['num_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(params['model_path']):\n",
    "    os.makedirs(params['model_path'])\n",
    "if not os.path.exists(params['sample_path']):\n",
    "    os.makedirs(params['sample_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(params['db'], params['z_dim'], params['cc_dim'], params['dc_dim'])\n",
    "discriminator = Discriminator(params['db'], params['cc_dim'], params['dc_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_optimizer = optim.Adam(generator.parameters(), params['lrD'], [params['beta1'], params['beta2']])\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), params['lrG'], [params['beta1'], params['beta2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = to_variable(torch.Tensor(np.zeros((params['sample_size'], params['z_dim']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jperalta/infogan/InfoGan.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out[:, self.cc_dim + 1:self.cc_dim + 1 + self.dc_dim] = F.softmax(out[:, self.cc_dim + 1:self.cc_dim + 1 + self.dc_dim].clone())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step[938/938], d_loss: -2.9793, g_loss: -0.8175\n",
      "Epoch [2/30], Step[938/938], d_loss: -2.3423, g_loss: 0.15246\n",
      "Epoch [3/30], Step[938/938], d_loss: -2.3509, g_loss: 0.28777\n",
      "Epoch [4/30], Step[938/938], d_loss: -2.7280, g_loss: -0.4912\n",
      "Epoch [5/30], Step[938/938], d_loss: -2.0280, g_loss: -1.0066\n",
      "Epoch [6/30], Step[938/938], d_loss: -2.1530, g_loss: 0.98776\n",
      "Epoch [7/30], Step[938/938], d_loss: -2.8184, g_loss: -0.2426\n",
      "Epoch [8/30], Step[938/938], d_loss: -2.5938, g_loss: -0.5026\n",
      "Epoch [9/30], Step[938/938], d_loss: -2.7501, g_loss: 1.93634\n",
      "Epoch [10/30], Step[938/938], d_loss: -2.8228, g_loss: 0.90130\n",
      "Epoch [11/30], Step[938/938], d_loss: -2.9120, g_loss: -0.3029\n",
      "Epoch [12/30], Step[938/938], d_loss: -2.6339, g_loss: -1.0085\n",
      "Epoch [13/30], Step[938/938], d_loss: -3.0885, g_loss: 0.79339\n",
      "Epoch [14/30], Step[938/938], d_loss: -2.9795, g_loss: 2.11532\n",
      "Epoch [15/30], Step[938/938], d_loss: -2.7708, g_loss: 0.09476\n",
      "Epoch [16/30], Step[938/938], d_loss: -2.8009, g_loss: 1.18719\n",
      "Epoch [17/30], Step[938/938], d_loss: -2.6154, g_loss: 0.29211\n",
      "Epoch [18/30], Step[938/938], d_loss: -2.5961, g_loss: 0.89325\n",
      "Epoch [19/30], Step[938/938], d_loss: -2.2977, g_loss: 0.21945\n",
      "Epoch [20/30], Step[938/938], d_loss: -2.7416, g_loss: -0.9382\n",
      "Epoch [21/30], Step[938/938], d_loss: -2.5391, g_loss: 1.12475\n",
      "Epoch [22/30], Step[938/938], d_loss: -2.0849, g_loss: 0.10765\n",
      "Epoch [23/30], Step[938/938], d_loss: -3.2357, g_loss: 0.07241\n",
      "Epoch [24/30], Step[938/938], d_loss: -2.8963, g_loss: 2.26807\n",
      "Epoch [25/30], Step[938/938], d_loss: -1.4152, g_loss: 0.20511\n",
      "Epoch [26/30], Step[938/938], d_loss: -0.3073, g_loss: 1.08079\n",
      "Epoch [27/30], Step[938/938], d_loss: -1.0885, g_loss: -0.7469\n",
      "Epoch [28/30], Step[938/938], d_loss: -2.7264, g_loss: 0.15957\n",
      "Epoch [29/30], Step[938/938], d_loss: -2.7438, g_loss: 0.64468\n",
      "Epoch [30/30], Step[938/938], d_loss: -2.4868, g_loss: 1.03020\r"
     ]
    }
   ],
   "source": [
    "total_step = len(data_loader) \n",
    "for epoch in range(params['num_epochs']):\n",
    "    print('')\n",
    "    for i,  images in enumerate(data_loader):\n",
    "        # ===================== Train Discriminator =====================#\n",
    "        images = to_variable(images[0]) # remove Label\n",
    "\n",
    "        batch_sz = images.size(0)\n",
    "        noise = to_variable(gen_cc(batch_sz, params['z_dim']))\n",
    "        \n",
    "        cc = to_variable(gen_cc(batch_sz, params['cc_dim']))\n",
    "        dc = to_variable(gen_cc(batch_sz, params['dc_dim']))\n",
    "        \n",
    "        # Fake -> Fake & Real -> Real\n",
    "        fake_images = generator(torch.cat((noise, cc, dc),1))\n",
    "        d_output_real = discriminator(images)\n",
    "        d_output_fake = discriminator(fake_images)\n",
    "        \n",
    "        d_loss_a = -torch.mean(torch.log(d_output_real[:,0]) + torch.log(1 - d_output_fake[:,0]))\n",
    "        \n",
    "        # Mutual Information Loss\n",
    "        output_cc = d_output_fake[:, 1:1 + params['cc_dim']]\n",
    "        output_dc = d_output_fake[:,   1 + params['cc_dim']:]\n",
    "        d_loss_cc = torch.mean((((output_cc - 0.0) / 0.5) ** 2))\n",
    "        d_loss_dc = -(torch.mean(torch.sum(dc * output_dc, 1)) + torch.mean(torch.sum(dc * dc, 1)))\n",
    "        \n",
    "        d_loss = d_loss_a + params['continuous_weight'] * d_loss_cc + 1.0 * d_loss_dc\n",
    "        \n",
    "        # Optimization\n",
    "        discriminator.zero_grad()\n",
    "        d_loss.backward(retain_graph=True)\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # ===================== Train Generator =====================#\n",
    "        g_loss_a = -torch.mean(torch.log(d_output_fake[:,0]))\n",
    "\n",
    "        g_loss = g_loss_a + params['continuous_weight'] * d_loss_cc + 1.0 * d_loss_dc\n",
    "\n",
    "        # Optimization\n",
    "        generator.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        # print the log info\n",
    "        if (i + 1) % params['log_step'] == 0 or (i + 1) == total_step:\n",
    "            sys.stdout.write('Epoch [%d/%d], Step[%d/%d], d_loss: %.4f, g_loss: %.4f\\r'\n",
    "                  % (epoch + 1, params['num_epochs'], i + 1, total_step, d_loss.item(), g_loss.item()))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # save the sampled images (10 Category(Discrete), 10 Continuous Code Generation : 10x10 Image Grid)\n",
    "        if (i + 1) % params['sample_step'] == 0:\n",
    "            tmp = np.zeros((params['sample_size'], params['cc_dim']))\n",
    "            for k in range(10):\n",
    "                tmp[k * 10:(k + 1) * 10, 0] = np.linspace(-2, 2, 10)\n",
    "            cc = to_variable(torch.Tensor(tmp))\n",
    "            tmp = np.zeros((params['sample_size'], params['dc_dim']))\n",
    "            for k in range(10):\n",
    "                tmp[k * 10:(k + 1) * 10, k] = 1\n",
    "            dc = to_variable(torch.Tensor(tmp))\n",
    "\n",
    "            fake_images = generator(torch.cat((fixed_noise, cc, dc), 1))\n",
    "            torchvision.utils.save_image(denorm(fake_images.data),\n",
    "                                         os.path.join(params['sample_path'],\n",
    "                                                      'generated-%d-%d.png' % (epoch + 1, i + 1)), nrow=10)\n",
    "\n",
    "    # save the model parameters for each epoch\n",
    "    g_path = os.path.join(params['model_path'], 'generator-%d.pkl' % (epoch + 1))\n",
    "    torch.save(generator.state_dict(), g_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = next(iter(data_loader))[0].cuda()\n",
    "batch_size = images.size(0)\n",
    "noise = to_variable(torch.randn(batch_size, params['z_dim']))\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = to_variable(gen_cc(batch_size, params['cc_dim']))\n",
    "dc = to_variable(gen_dc(batch_size, params['dc_dim']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cat((noise, cc, dc),1).size()\n",
    "fake_images = generator(torch.cat((noise, cc, dc),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_output_real = discriminator(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd_output_real' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c78f399b9197>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md_output_real\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'd_output_real' is not defined"
     ]
    }
   ],
   "source": [
    "d_output_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
